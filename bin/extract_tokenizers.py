#!/usr/bin/env python3

import argparse
from pathlib import Path

EXTRACT_FROM = """
//
// tokenizer
//
"""

EXTRACT_TO = """
//
// sampling
//
"""

EXTRACT_HEADER = """
// This file is automatically generated by bin/extract_tokenizers.py

#include <string>
#include <vector>
#include <queue>

#include "extracted.h"
"""

EXTRACT_H_HEADER = """
// This file is automatically generated by bin/extract_tokenizers.py

#pragma once

#include <string>
#include <vector>

typedef int llama_token;
typedef int llama_v2_token;
"""

EXTRACT_H_FORWARD_DECLARATIONS = """
std::vector<llama_vocab::id> llama_tokenize(const llama_vocab & vocab, const std::string & text, bool bos);
std::vector<llama_v2_vocab::id> llama_v2_tokenize(const llama_v2_vocab & vocab, const std::string & text, bool bos);
std::vector<llama_v2_token> legacy_llama_v2_tokenize(const llama_v2_vocab & vocab, const std::string & text, bool bos);
"""

ALIAS_LLAMA_TOKEN_FNS_TO_V2 = """
#define llama_v2_token_bos llama_token_bos
#define llama_v2_token_eos llama_token_eos
#define llama_v2_token_nl llama_token_nl
"""


def extract_code(contents: str, extract_from: str, extract_to: str) -> str:
    start = contents.find(extract_from)
    end = contents.find(extract_to, start)
    if start == -1 or end == -1:
        raise ValueError("Could not find code to extract")
    code = contents[start:end]
    return code


def extract_until_matching_braces(contents: str, extract_from: str) -> str:
    start = contents.find(extract_from)
    if start == -1:
        raise ValueError("Could not find code to extract")
    code = contents[start:]
    braces = 0
    end = 0
    for i, c in enumerate(code):
        if c == '{':
            braces += 1
        elif c == '}':
            braces -= 1
            if braces == 0:
                end = i + 1
                break
    while end < len(code) and code[end] not in ['\n', '\r']:
        end += 1
    return code[:end]


def fn_strip_static(contents: str, fn_signature: str) -> str:
    start = contents.find(fn_signature)
    if start == -1:
        raise ValueError("Could not find function to strip static from")
    # go to beginning of line, and then strip the static
    while start > 0 and contents[start] != '\n':
        start -= 1
    contents = contents[:start] + contents[start:].replace('static ', '')
    return contents


def main(path: Path) -> None:
    output_path = Path(__file__).parent.parent / 'src' / 'extracted.cpp'
    output_h_path = Path(__file__).parent.parent / 'src' / 'extracted.h'

    # main llama.cpp tokenizer
    llama_cpp = path.joinpath('llama.cpp').read_text()

    fn_llama_token_bos = extract_until_matching_braces(llama_cpp, 'llama_token llama_token_bos()')
    fn_llama_token_eos = extract_until_matching_braces(llama_cpp, 'llama_token llama_token_eos()')
    fn_llama_token_nl = extract_until_matching_braces(llama_cpp, 'llama_token llama_token_nl()')

    struct_llama_vocab = extract_until_matching_braces(llama_cpp, 'struct llama_vocab')
    main_tokenizer = extract_code(llama_cpp, EXTRACT_FROM, EXTRACT_TO)
    main_tokenizer = fn_strip_static(main_tokenizer, 'std::vector<llama_vocab::id> llama_tokenize(')

    # old v2 tokenizer
    llama_v2_cpp = path.joinpath('otherarch', 'llama_v2.cpp').read_text()

    struct_llama_v2_vocab = extract_until_matching_braces(llama_v2_cpp, 'struct llama_v2_vocab')
    v2_main_tokenizer = extract_code(llama_v2_cpp, EXTRACT_FROM, EXTRACT_TO)
    v2_main_tokenizer = fn_strip_static(v2_main_tokenizer, 'std::vector<llama_v2_vocab::id> llama_v2_tokenize(')

    v2_legacy_tokenizer = extract_until_matching_braces(llama_v2_cpp, '#define MAX_TOKEN_LEN 18')

    output_lines = [
        EXTRACT_HEADER,
        fn_llama_token_bos,
        fn_llama_token_eos,
        fn_llama_token_nl,
        ALIAS_LLAMA_TOKEN_FNS_TO_V2,
        main_tokenizer,
        "//\n// old v2 tokenizer\n//",
        v2_main_tokenizer,
        v2_legacy_tokenizer,
    ]

    h_output_lines = [
        EXTRACT_H_HEADER,
        struct_llama_vocab,
        struct_llama_v2_vocab,
        EXTRACT_H_FORWARD_DECLARATIONS,
    ]

    output_lines = [line + '\n\n' for line in output_lines]
    h_output_lines = [line + '\n\n' for line in h_output_lines]

    with output_path.open('w') as f:
        f.writelines(output_lines)

    with output_h_path.open('w') as f:
        f.writelines(h_output_lines)


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument("koboldcpp_dir", type=Path, help="Path to koboldcpp's source code")
    args = parser.parse_args()

    main(args.koboldcpp_dir)
